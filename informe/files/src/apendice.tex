% === demo 1 === %
\subsection{A: $A = pWD + ez^t$}\label{A.1}
\begin{proof}[demostración] 
    
Recordemos que:

\begin{align*}
    e_i     &=  1
    \\
    \\
    z_{j}   &=  \left\{ 
                    \begin{array}{lcc}
                    (1 - p) / n     &  \ \text{si}    &  c_j \neq 0 \\
                    1 / n           &  \ \text{si no} &
                    \end{array}
                \right.\
    \\
    \\
    w_{ij}  &=  \left\{ 
                    \begin{array}{lcc}
                    1               &  \qquad \qquad \text{si}    & i \neq j\  \wedge\ j \stackrel{l}{\longrightarrow} i \\
                    0               &  \qquad \qquad \text{si no} &
                    \end{array}
                \right.\
    \\
    \\
    d_{ij}  &=  \left\{ 
                    \begin{array}{lcc}
                    1 / c_j         &  \qquad \: \: \text{si}    & i = j\  \wedge\ c_j \neq 0 \\
                    0               &  \qquad \ \  \text{si no} &
                    \end{array}
                \right.\
\end{align*}
\vspace{1em}

\noindent A partir de estas definiciones, vemos que, como $\textbf{D}$ es diagonal, el producto a derecha $\textbf{W}\textbf{D}$ escala cada columna $w_j$ por el factor $d_{jj}$, tal que:
\vspace{1em}

\begin {equation*}
    (\textbf{W}\textbf{D})_{ij}  =  \left\{ 
                    \begin{array}{lcc}
                    w_{ij} / c_j    & \ \ \ \ \ \text{si}    & c_j \neq 0 \\
                    0               & \ \ \ \ \ \text{si no} &
                    \end{array}
                \right.\
\end {equation*}
\vspace{1em}

\noindent Como $p$ es un escalar, sigue entonces que:
\vspace{1em}

\begin {equation*}
    (p\textbf{W}\textbf{D})_{ij}  =   \left\{ 
                        \begin{array}{lcc}
                        p \cdot w_{ij} / c_j    &  \text{si}    & c_j \neq 0 \\
                        0                       &  \text{si no} &
                        \end{array}
                    \right.\
\end {equation*}
\vspace{1em}

\noindent Además, $\ e \in \mathbb{R}^{n \times 1}\ \wedge\ z^t \in \mathbb{R}^{1 \times n} \implies ez^t \in \mathbb{R}^{n \times n}\ $, y:
\vspace{1em}

\begin {equation*}
    (ez^t)_{ij} := \sum_{k=1}^{1} e_{ik} \cdot z^t_{kj} = e_i \cdot z^t_j = 1 \cdot z^t_j = z_j 
\end {equation*}
\vspace{1em}

\noindent Por lo que:
\begin {align*}
    (p\textbf{W}\textbf{D} + ez^t)_{ij}   &=   \left\{ 
                                \begin{array}{lcc}
                                p \cdot w_{ij} / c_j + z_j   &  \ \ \ \ \qquad \text{si}    & c_j \neq 0 \\
                                z_j                          &  \ \ \ \ \qquad \text{si no} &
                                \end{array}
                            \right.\ \\
                            \\
                        &=  \left\{ 
                                \begin{array}{lcc}
                                (1 - p) \cdot \frac{1}{n} + p \cdot \frac{w_{ij}}{c_j}   &  \ \ \   \text{si}    & c_j \neq 0 \\
                                \frac {1}{n}                                             &  \ \ \   \text{si no} &
                                \end{array}
                            \right.\
\end {align*}

\noindent pero: 
\vspace{1em}

\begin{equation*}
    a_{ij} := Pr(j \longrightarrow i) = \left\{ 
                                            \begin{array}{lcc}
                                            (1 - p)\cdot \frac{1}{n} + p \cdot \frac{I_{ij}}{c_j}      &  \text{si}    & c_j \neq 0\\
                                            \frac{1}{n}                                                &  \text{si no}  &
                                            \end{array}
                                        \right.
\end{equation*}
\vspace{1em}

Como $\ I_{ij} = 1\ $ si y sólo si existe un hipervínculo de $j$ a $i$, con $j \neq i$ ---y nulo en caso contrario---, entonces $\ I_{ij} = w_{ij}\ $ y concluímos que $\ a_{ij} = (p\textbf{W}\textbf{D} + ez^t)_{ij}$, $\forall i, j:\ 1\ ...\ n\ $,  lo que implica que:
\vspace{1em}

\begin{equation*}
    \textbf{A} = p\textbf{W}\textbf{D} + ez^t
\end{equation*}
\vspace{1em}

\end{proof}



% === demo 2 === %
\subsection{B: $I - pWD$ permite la eliminación gaussiana}\label{A.2}

Definimos la eliminación Gaussiana de la siguiente manera:

\begin{equation*}
\textbf{A} := \textbf{I} - p\textbf{WD}
\end{equation*}

\begin{align*}
    \textbf{Eg}_{1}(\textbf{A}) \ \ \  &=   \textbf{A}
                            \\
    \textbf{Eg}_{k+1}(\textbf{A})_{ij}  &=  \left\{ 
                                    \begin{array}{lcc}
                                    \textbf{Eg}_{k}(\textbf{A})_{ij}  &   \text{si}    & i < k+1 \ \vee \  j < k+1 \\
                                    \textbf{Eg}_{k}(\textbf{A})_{ij} - \frac {\textbf{Eg}_{k}(\textbf{A})_{ik} \ \cdot \ \textbf{Eg}_{k}(\textbf{A})_{kj}}{\textbf{Eg}_{k}(\textbf{A})_{kk}}    &  \ \ \ \  \text{si no} &
                                    \end{array}
                                \right.\
\end{align*}

\begin{align*}
    HI: (\forall j \in \mathbb{N}) (k \ \leq \ j \ \leq \ N ) &\longrightarrow_L |\textbf{Eg}_{k}(\textbf{A})_{jj}| \geq \sum_{i=k, \ i \neq j}^{N} |\textbf{Eg}_{k}(\textbf{A})_{ij}| \\
    \noindent CB: (k = 1) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
    (\forall j \in \mathbb{N}) (1 \ \leq \ j \ \leq \ N ) &\longrightarrow_L |\textbf{A}_{jj}| \geq \sum_{i=1, \ i \neq j}^{N} |\textbf{A}_{ij}| \\
    (\forall j \in \mathbb{N}) (1 \ \leq \ j \ \leq \ N ) &\longrightarrow_L 1 \geq \sum_{i=1, \ i \neq j}^{N} |(1/C_j \vee 0)| \\
    (\forall j \in \mathbb{N}) (1 \ \leq \ j \ \leq \ N ) &\longrightarrow_L 1 \geq (|p/C_j| \vee 0) \cdot C_j \\
    (\forall j \in \mathbb{N}) (1 \ \leq \ j \ \leq \ N ) &\longrightarrow_L 1 \geq |p| > (|p/C_j| \vee 0) \cdot C_j \\
    \text{sabemos : } 0 < p < 1  &\rightarrow 1 \geq |p| \\
    (\forall j \in \mathbb{N}) (1 \ \leq \ j \ \leq \ N ) &\longrightarrow_L \ \text{True} \\ 
    \text{QVQ:} (\forall j \in \mathbb{N}) (k+1 \ \leq \ j \ \leq \ N ) &\longrightarrow_L |\textbf{Eg}_{k+1}(\textbf{A})_{jj}| \geq \sum_{i=k+1, \ i \neq j}^{N} |\textbf{Eg}_{k+1}(\textbf{A})_{ij}| \\
    \longrightarrow_L |\textbf{Eg}_{k}(\textbf{A})_{jj} - \frac {\textbf{Eg}_{k}(\textbf{A})_{jk} \ \cdot \ \textbf{Eg}_{k}(\textbf{A})_{kj}}{\textbf{Eg}_{k}(\textbf{A})_{kk}}| \geq &\sum_{i=k+1, \ i \neq j}^{N} |\textbf{Eg}_{k}(\textbf{A})_{ij} - \frac {\textbf{Eg}_{k}(\textbf{A})_{ik} \ \cdot \ \textbf{Eg}_{k}(\textbf{A})_{kj}}{\textbf{Eg}_{k}(\textbf{A})_{kk}}| \\
    \longrightarrow_L |\textbf{Eg}_{k}(\textbf{A})_{jj}| - |\frac {\textbf{Eg}_{k}(\textbf{A})_{jk} \ \cdot \ \textbf{Eg}_{k}(\textbf{A})_{kj}}{\textbf{Eg}_{k}(\textbf{A})_{kk}}| \geq &\sum_{i=k+1, \ i \neq j}^{N} |\textbf{Eg}_{k}(\textbf{A})_{ij}| +  \sum_{i=k+1, \ i \neq j}^{N} |\frac{\textbf{Eg}_{k}(\textbf{A})_{ik} \ \cdot \ \textbf{Eg}_{k}(\textbf{A})_{kj}}{\textbf{Eg}_{k}(\textbf{A})_{kk}}| \\
    \sum_{i=k+1, \ i \neq j}^{N} |\textbf{Eg}_{k}(\textbf{A})_{ij}| = &\sum_{i=k, \ i \neq j}^{N} (|\textbf{Eg}_{k}(\textbf{A})_{ij}|) -  |\textbf{Eg}_{k}(\textbf{A})_{kj}|\\
    \text{Por HI: } |\textbf{Eg}_{k}(\textbf{A})_{jj}| - |\textbf{Eg}_{k}(\textbf{A})_{kj}| \geq &\sum_{i=k, \ i \neq j}^{N} (|\textbf{Eg}_{k}(\textbf{A})_{ij}|) -  |\textbf{Eg}_{k}(\textbf{A})_{kj}|\\
    |\textbf{Eg}_{k}(\textbf{A})_{jj}| - |\frac {\textbf{Eg}_{k}(\textbf{A})_{jk} \ \cdot \ \textbf{Eg}_{k}(\textbf{A})_{kj}}{\textbf{Eg}_{k}(\textbf{A})_{kk}}| \geq |\textbf{Eg}_{k}&(\textbf{A})_{jj}| - |\textbf{Eg}_{k}(\textbf{A})_{kj}| +  \sum_{i=k+1, \ i \neq j}^{N} |\frac{\textbf{Eg}_{k}(\textbf{A})_{ik} \ \cdot \ \textbf{Eg}_{k}(\textbf{A})_{kj}}{\textbf{Eg}_{k}(\textbf{A})_{kk}}| \\
    |\textbf{Eg}_{k}(\textbf{A})_{kj}| - |\frac {\textbf{Eg}_{k}(\textbf{A})_{jk} \ \cdot \ \textbf{Eg}_{k}(\textbf{A})_{kj}}{\textbf{Eg}_{k}(\textbf{A})_{kk}}| \geq  &\frac{ |\textbf{Eg}_{k}(\textbf{A})_{kj}|}{|\textbf{Eg}_{k}(\textbf{A})_{kk}|} \sum_{i=k+1, \ i \neq j}^{N} |\textbf{Eg}_{k}(\textbf{A})_{ik}|\\
    \sum_{i=k+1, \ i \neq j}^{N} |\textbf{Eg}_{k}(\textbf{A})_{ik}| = &\sum_{i=k+1}^{N} (|\textbf{Eg}_{k}(\textbf{A})_{ik}|) -  |\textbf{Eg}_{k}(\textbf{A})_{jk}|\\
    \text{Por HI: } |\textbf{Eg}_{k}(\textbf{A})_{kk}| -  |\textbf{Eg}_{k}(\textbf{A})_{jk}| \geq &\sum_{i=k+1}^{N} (|\textbf{Eg}_{k}(\textbf{A})_{ik}|) -  |\textbf{Eg}_{k}(\textbf{A})_{jk}|\\
    |\textbf{Eg}_{k}(\textbf{A})_{kj}| - |\frac {\textbf{Eg}_{k}(\textbf{A})_{jk} \ \cdot \ \textbf{Eg}_{k}(\textbf{A})_{kj}}{\textbf{Eg}_{k}(\textbf{A})_{kk}}| \geq  &\frac{ |\textbf{Eg}_{k}(\textbf{A})_{kj}|}{|\textbf{Eg}_{k}(\textbf{A})_{kk}|} (|\textbf{Eg}_{k}(\textbf{A})_{kk}| -  |\textbf{Eg}_{k}(\textbf{A})_{jk}|)\\
    |\textbf{Eg}_{k}(\textbf{A})_{kj}| - |\frac {\textbf{Eg}_{k}(\textbf{A})_{jk} \ \cdot \ \textbf{Eg}_{k}(\textbf{A})_{kj}}{\textbf{Eg}_{k}(\textbf{A})_{kk}}| \geq  &|\textbf{Eg}_{k}(\textbf{A})_{kj}| - |\frac {\textbf{Eg}_{k}(\textbf{A})_{jk} \ \cdot \ \textbf{Eg}_{k}(\textbf{A})_{kj}}{\textbf{Eg}_{k}(\textbf{A})_{kk}}|\\
    (\forall j \in 	\mathbb{N}) (1 \ \leq \ j \ \leq \ N ) &\longrightarrow_L \ \text{True} \\ 
\end{align*}

QED que $(\forall j \in \mathbb{N}) (k \ \leq \ j \ \leq \ N ) \longrightarrow_L |\textbf{Eg}_{k}(\textbf{A})_{jj}| \geq \sum_{i=k, \ i \neq j}^{N} |\textbf{Eg}_{k}(\textbf{A})_{ij}|$\\
Por ende el elemento $|\textbf{Eg}_{k}(\textbf{A})_{kk}| = 0 \leftrightarrow \sum_{i=k+1}^{N} |\textbf{Eg}_{k}(\textbf{A})_{ik}| = 0$
O sea que el elemento de la diagonal en cada paso de la eliminacion gaussiana es 0 si y solo si todos los elementos que tiene por debajo en su columna son 0 o sea que se podria saltear ese paso


 


% === estructuras alternativas === %
\subsection{C: Estructuras alternativas}\label{A.3}