\vspace{1em}

\subsection{Análisis cuantitativo}\label{cuantitativo} Se procederá a evaluar una implementación de $PageRank$ en C++ acorde a los algoritmos propuestos.

\vspace{2em}
\subsubsection{Error relativo} Medimos el error $|\mathbf{A}x - x|_1$ en función del valor de $p$ para cien grafos generados aleatoriamente. En total, obtuvimos 10,000 mediciones\footnote{El script asociado se puede encontrar en $./experimentos/error\_relativo.py$}.  
\vspace{1em}

\noindent \textsc{Metodología}. Se calculó  $x = PageRank(g,\ p)$ y se midió el error relativo $|\mathbf{A}x - x|_1$ para cada uno de los grafos sobre cada valor de $p$ en en el intervalo $(0, 1)$ de a saltos de $0.01$.
\vspace{1em}

\noindent Cada caso, representable por una matriz de conectividad W $\in \{0,\ 1\}^{100 \times 100}$, se generó a través del siguiente procedimiento\footnote{Se utilizó un valor semilla para facilitar la reproducibilidad.}:
\vspace{1em}

\begin{enumerate}
    \item Se eligió  la cantidad de ejes (e) del sistema de manera uniforme sobre el intervalo $[0,\ R \cdot T)$, donde $T = 100^2 - 100$ representa el máximo de ejes posibles en un grafo de cien nodos sin auto-direccionamiento y $R = 1/4$ es un valor arbitrario definido para imitar las carácteristicas de ralidad esperables en un conjunto de páginas web.
    \item Se pobló una matriz $W_0 \in \{0,\ 1\}^{99 \times 100} = 0$ con unos en las primeras `e' posiciones y se utilizó el algoritmo de shuffle de numpy, sobre el rng \textsc{PCG64}, para generar una permutación aleatoria.
    \item Se expandió la misma con ceros en la diagonal para lograr la matríz $W \in \{0, 1\}^{100 \times 100}$. 
\end{enumerate}
\vspace{1em}


\noindent \textsc{Observaciones}. El experimento tiene como limitaciones principales el tamaño de la muestra (cien grafos distintos) y el método de generación de casos ---los mismos no provienen de muestras reales---, que incluye la elección arbitraria del valor $R$. Sin embargo, contempla con cierta granularidad todo el expectro de valores posibles para $p$, tal que permite conocer el error relativo de los resultados en función de su parámetro `libre'.
\vspace{1em}


\noindent \textsc{Resultados}. El cuadro 1. resume los resultados obtenidos. 
\vspace{1.5em}

\begin{center}
    \begin{tabular}{ |l|c| } 
     \hline
    mediciones              & 10000         \\
    error relativo promedio & 0.00084646    \\
    desviación estándar     & 0.00063764    \\
    mínimo                  & 1.7347e-16    \\
    25\%                    & 0.00034960    \\
    50\%                    & 0.00075431    \\
    75\%                    & 0.00121044    \\
    máximo                  & 0.00376671    \\
    \hline
    \end{tabular} \\
    \bigskip
    Cuadro 1. datos de resumen del experimento. 
\end{center}
\vspace{1em}

Podemos observar que el error relativo fue en promedio menor a $1e-3$. De distribuirse uniformemente, esto nos permite suponer que el error relativo de cada puntaje debe estar en el orden de $1e-5$.
\vspace{1em}

La Figura \ref{img_error_relativo}. muestra la distribución de los resultados en función del parámetro $p$.

\fig[]{files/src/media/error_relativo_x_p_val.png}{Error relativo promedio -en base a una norma L1- e intervalo de confianza del 95\% para una muestra aleatoria de cien grafos en función de $p$. }{img_error_relativo}{}
\vspace{1em}

Notar la progresiva disminución del error a medida que $p$ se aproxima a 1. Los máximos locales se encuentran en $p = 0.16$ (0.00101828)  y $p = 0.55$ (0.00117609). El mínimo local en $p = 0.26$ (0.00056232)\footnote{El cálculo de los picos locales se puede encontrar en $./experimentos/resultados/error\_relativo$}. 

\vspace{1em}
Si bien el tamaño de la muestra y su método de generación no permiten sacar conclusiones fuertes al respecto de los resultados, sí podemos notar que el valor de $p$ influencia el error relativo. Desde un punto de vista numérico esto tiene sentido, dado que $p$ reduce la  magnitud de los valores sobre los que trabaja el algoritmo. Sin embargo, la forma particular de la distribución del error en función de $p$ resultó sorpresiva. 

\vspace{1em}
A modo de consideración para futuros análisis, podemos mencionar que nuestro método de `corte' ---cualquier valor menor a $1e-4$ se anula--- también debe influir en el error de los resultados. 


\newpage
\subsubsection{Error absoluto} Medimos el error $|x - \hat{x}|_1$ para los casos de test provistos por la cátedra\footnote{El script asociado se puede encontrar en $./experimentos/error\_tests.py$. Los resultados coordenada a coordenada se pueden observar en $./experimentos/resultados/error\_tests$.}. 
\vspace{1em}

\noindent El Cuadro 2. resume los resultados.
\vspace{1.5em}

\begin{center}
    \begin{tabular}{ |l|c| } 
    \hline
    test                         & error        \\
    \hline
    test\_15\_segundos           & 0.0291137    \\
    test\_30\_segundos           & 0.0229572    \\
    test\_aleatorio              & 6.176e-07    \\
    test\_aleatorio\_desordenado & 6.176e-07    \\
    test\_completo               & 0.0          \\
    test\_sin\_links             & 0.0          \\
    test\_trivial                & 0.0          \\
    \hline
    \end{tabular} \\
    \bigskip
    Cuadro 2. Error absoluto en base a la -norma L1- de los tests. 
\end{center}
\vspace{1em}

Podemos observar que hay cierta correlación entre la cantidad de páginas y el error. Esto tiene sentido dado que la norma L1 es la suma del valor absoluto de las coordenadas. Mientras mayor sea la dimensión, mayor será la cantidad de errores a sumar.




\newpage
\subsection{Análisis cualitativo} Para entender en profundidad las propiedades de $PageRank$, decidimos evaluar distintos escenarios `simples' de grafos. Comenzamos por los casos triviales.




\vspace{2em}
\subsubsection{Escenario 1: Sin Links} Ninguna página tiene un vínculo a ninguna otra. Este es el caso base que el \textit{modelo del navegante aleatorio} busca resolver respecto a modelos anteriores. 

\vspace{1em}
\fig[]{files/src/media/conceptuales/sin_links.png}{Una web con seis páginas desvinculadas.}{sin_links}{0.20}

\vspace{1em}
\noindent \textsc{Metodología}. Se generaron cien conjuntos de páginas web sin links donde se varió la cantidad total de sitios (de uno a cien). Se midió el puntaje de cada uno en los rankings obtenidos. 

\vspace{1em}
\noindent \textsc{Resultados}. Observamos que el puntaje de todas las páginas fue igual en cada caso, pero fue decrementando en función de la cantidad total de nodos. 

\vspace{1em}
\fig[]{files/src/media/sin_links.png}{El puntaje de una página testigo en función de la cantidad de páginas para conjuntos sin links.}{resultado_sin_links}{}

\vspace{1em}
El puntaje obtenido para cada página fue de $\frac{1}{n}$. La figura \ref{resultado_sin_links}. grafica los resultados para un caso testigo. Esto se explica teóricamente: si no hay links en la web, entonces la matriz de conectividad $\mathbf{W}$ es nula y $\mathbf{I} - p\mathbf{W}\mathbf{D} = \mathbf{I}$. Como $\mathbf{I}x = 1 \implies x_i = 1$. Al normalizar nos queda que $x_i = \frac{1}{n}\ \forall i: 1\ ...\ n$. 

\vspace{1em}
El resultado es coherente con la interpretación intuitiva del ranking: si ninguna página redirige a ninguna otra, entonces un navegante solo podrá acceder a los sitios del conjunto de manera aleatoria. El modelo define esta probabilidad de manera uniforme sobre el total de las páginas. A mayor cantidad de páginas, menor la probabilidad que el navegante aleatorio termine en un sitio en particular.




\vspace{2em}
\subsubsection{Escenario 2: Simetría} Otro escenario trivial es en el que todas las paginas tienen links a todas las demás. 

\vspace{1em}
\fig[]{files/src/media/conceptuales/todos_con_todos.png}{Una web simétrica dónde cada nodo apunta al resto.}{todos_con_todos}{0.26}

\vspace{1em}
\noindent \textsc{Metodología}. Para analizar esta situación, se generaron cien casos distintos donde se varió la cantidad de nodos (entre uno y cien) y se mantuvo la simetría de las relaciones. En el primero caso, se compuso una web con un único nodo. Luego, con dos nodos apuntándose mutuamente y así progresivamente hasta llegar a cien nodos donde cada uno apuntó al resto.

\vspace{1em}
\noindent \textsc{Resultados}. Observamos que el puntaje de cada una de las páginas fue igual para cada caso particular\footnote{Se puede ver el resultado de los experimentos en $./experimentos/resultados/todos\_con\_todos$.} pero que este valor fue decrementando a medida que aumentó la cantidad de sitios. Luego de observar el resultado notamos que para cada $n$ el mismo fue equivalente al escenario "sin links".

Esto tiene sentido ya que si todos los nodos se apuntan entre sí, el sistema es totalmente simétrico, y sería ilógico que alguno tenga más importancia que los demás. 

\vspace{1em}
\noindent Pudimos notar la misma clase de relación con otras estructuras simétricas. Por ejemplo, en estructuras de referencias circulares\footnote{Ver $./experimentos/resultados/circular$}.



\vspace{2em}
\subsubsection{Escenario 3: Todos con uno} Para esta estructura, tal y como su nombre indica, todas las páginas tendrán un enlace con una única página. Se la referirá durante esta subsección como \textit{'uno'}. Además, cualquier otro tipo de relación será nula. Los enlaces que unen al 'uno' serán únicamente enlaces de 'ida', por lo que, si bien el \textit{'uno'} recibirá $n$ enlaces, este no tendrá ninguno señalando a otro.

\vspace{1em}
\fig[]{files/src/media/conceptuales/todos_a_uno_3.png}{Una web centralizada, donde todos los nodos señalan a la misma página.}{todos_con_uno}{0.26}

\vspace{1em}
\noindent \textsc{Metodología}. Se generaron cien casos distintos donde se varió la cantidad de enlaces que conectan con el \textit{'uno'} y se midió su puntaje. Se controló la cantidad de nodos (cien) y se evitaron otros vínculos. De esta forma, veremos la evolución de una web a medida que el \textit{'uno'} va siendo referenciado.

\vspace{1em}
\noindent \textsc{Hipótesis}. Consideramos que el puntaje se comportará de la siguiente forma:
\begin{itemize}
\item El \textit{'uno'} tendrá un ranking muy cercano a 1, que aumentará de tamaño de manera proporcional a la cantidad de páginas existentes. Estimamos que el crecimiento adoptará una curva similar a una logarítmica.
\item Las demás páginas tendrán un ranking muy cercano a 0, que disminuirá en relación al numero de enlaces existentes. Estimamos que el decrecimiento adoptará una curva similar a $\frac{1}{n}$.
\end{itemize}

\vspace{1em}
\noindent \textsc{Resultados}. Observamos que los resultados obtenidos distan un poco de los especulados\footnote{Se puede ver el resultado de los experimentos en $./experimentos/resultados/todos\_con\_uno$.}, ya que, si bien el decrecimiento del resto de las páginas fue de la forma descrita, el comportamiento del \textit{'uno'} no se comportó de manera logarítmica. Consideramos que es más parecida a alguna variante de $\sqrt{n}$. Esto nos llamó la atención.



\vspace{2em}
\subsubsection{Escenario 4: Uno con todos} Para esta estructura, veremos el caso inverso de la estructura anterior. En esta ocasión, una única página, que será referenciada nuevamente como \textit{'uno'}, tendrá enlaces salientes hacia todas las demás. Además, cualquier otro tipo de relación será nula. Los enlaces de \textit{'uno'} serán únicamente salientes, por lo que no recibirá ningún enlace.

\vspace{1em}
\fig[]{files/src/media/conceptuales/uno_a_todos_3.png}{Una web muy simétrica, donde todos, excepto \textit{'uno'} poseen el ranking máximo.}{uno_con_todos}{0.26}

\vspace{1em}
\noindent \textsc{Metodología}. Para analizar esta situación, se generaron cien casos distintos donde se varió la cantidad de enlaces salientes de \textit{'uno'}. De esta forma, veremos la evolución de una web a medida que el \textit{'uno'} va conectando con las demás páginas. Para evaluar los resultados de la evolución, graficamos las variaciones de tres páginas. La \textit{'uno'}, la primer página con la que conecta y la última con la que lo hace. Así, podremos ver la evolución desde varias perspectivas.

\vspace{1em}
\noindent \textsc{Hipótesis}. Suponemos que se comportará de la siguiente forma:
\begin{itemize}
\item La \textit{'uno'} tendrá un ranking significativamente menor que todas las demás páginas, disminuyendo a medida que aumenta el número de páginas. Estimamos que el decrecimiento adopte una curva similar al $\frac{1}{n}$.
\item Las demás páginas irán disminuyendo su ranking hasta cierto punto, donde alcanzarán un máximo, cuando \textit{'uno'} las conecte. Luego, seguirán disminuyendo su ranking hasta que todas posean el mismo, excepto \textit{'uno'}.
\end{itemize}

\vspace{1em}
\noindent \textsc{Resultados}. Observamos que los resultados difieren en gran forma de lo especulado para lo que es el \textit{'uno'}\footnote{Se puede ver el resultado de los experimentos en $./experimentos/resultados/uno\_con\_todos$.}, la disminución de su ranking fue abrupta ni bien se conectó el primer enlace. Por otro lado, las suposiciones hechas para los demás son tal cual se esperaban.




\vspace{2em}
\subsubsection{Escenario 5: Transitividad en Cadena} Cómo se transfiere el puntaje de un sitio a otro a medida que se extiende la cadena de páginas intermedias entre ambos.

\vspace{1em}
\fig[]{files/src/media/conceptuales/transitividad_en_cadena_3.png}{Una cadena de nodos.}{cadena}{0.4}

\vspace{1em}
Consideramos de interés ver cómo se ve afectado el puntaje de una página al ser apuntada por otra `importante', y cómo varía a medida que empiezan a haber más intermediarios en la relación. 

\vspace{1em}
\noindent \textsc{Metodología}. Se generaron cien instancias de test con 200 nodos cada una ---para controlar las variaciones del puntaje relacionadas a la inserción de nuevos nodos\footnote{Como se comprobó sucede en el Escenario 1.}--- y se estableció que las páginas indexadas en el rango (100, 200] apunten a la página $1$ y que el resto esté desvinculada. 

\vspace{1em}
\fig[]{files/src/media/cadena.png}{El puntaje del último eslabón en una cadena de vínculos, en función de su largo. Salvo la primer página, el resto de las páginas en la cadena no tiene otras relaciones.}{resultado_cadena}{}

\vspace{1em}
Se procedió a generar una cadena cuyo tamaño se incrementó en uno en cada instancia sucesiva del test: en la primera, el nodo `1' apuntó al nodo `2'; en la segunda, se extendió la cadena y el nodo `2' apuntó al nodo `3'; se procedió de igual forma hasta llegar al último nodo desvinculado. En cada instancia, se midió el puntaje del último nodo en la cadena.

\vspace{1em}
\noindent \textsc{Resultados}. Como se ve en la Figura \ref{resultado_cadena}. el puntaje del último eslabón se hace más chico a medida que la cadena se hace más larga. De igual manera, el resultado se acerca progresivamente a $1/l$, donde $l$ es el largo de la cadena. 

\vspace{1em}
Podemos ver que la influencia de la página `importante' es fuerte al principio, pero se diluye rápidamente en la cadena. Consideramos que el comportamiento es deseable: Si una página importante apunta a otra, entonces es esperable que aumente la probabilidad que un navegante decida acceder a éste segundo sitio. Pero si agregamos un tercer eslabón en la cadena, entonces la probabilidad que se acceda a ésta tercera página debería ser la intersección de las probabilidades anteriores, y en consecuencia más improbable. 




\vspace{2em}
\subsubsection{Escenario 6: Referencias Valiosas} Cómo varía el peso de una página a medida que cambia la importancia de las páginas que la referencian.
\vspace{1em}

Nuestra hipótesis es que inicialmente el peso del nodo `1' va a ser mayor que el del nodo `0', basándonos en que `0' no tiene páginas que la referencien y `1' tiene una referencia por ende va a ser mayor. Pero a medida que más y más nodos apunten a `0' el peso de éste va a superar al del nodo `1'. Sosteniéndonos en los resultados que obtuvimos a partir de ``Transitividad en Cadena" donde se observa que la importancia de un nodo se transmite a los nodos que apunta, consideramos que el peso de ambos va a ser creciente.

\vspace{1em}
\noindent \textsc{Metodología}. La manera en la que planteamos esta experimentación fue, generar 100 instancias de 102 nodos cada uno. Inicialmente el nodo `0' apunta al nodo `1' y todos los demás nodos permanecían aislados. En cada iteración del test se seleccionó uno de los nodos aislados y se agregó una referencia de este último al nodo `0', siguiendo esta dinámica hasta que no haya mas nodos aislados.
En cada una de estas iteraciones almacenamos por un lado el peso de `0' y por otro el peso de `1'.

\vspace{1em}
\noindent \textsc{Resultados}. 

\vspace{1em}
El resultado que obtuvimos cumplía parcialmente con lo esperado pero cambio nuestra percepción de PageRank, ya que inicialmente si se cumplió que el nodo `1' era mayor que `0' y que ambos pesos crecen a medida que `0' toma relevancia. Este comportamiento queda claramente plasmado en el gráfico donde se puede apreciar que el peso de ambos es creciente. 
Por otro lado, lo que no se cumplió y nos tomó por sorpresa, fue que el peso de `0' nunca superó al peso de `1', como se observa en el gráfico la curva que representa a `1' siempre esta por encima de la curva que representa el peso de `0'.

\vspace{1em}
Concluimos entonces que tener referencias valiosas es esencial para aumentar el peso en el ranking y que la influencia que tienen las páginas de mayor importancia puede generar cambios radicales en la valoración de PageRank.



\vspace{2em}
\subsubsection{Escenario 7: Referenciador Importante} Cómo varía el peso de un nodo importante a medida que referencia a más nodos. 

\vspace{1em}
\noindent \textsc{Metodología}. Planteamos un test donde había 20 nodos. Inicialmente todos los nodos apuntan a `0' y en cada iteración se agrega un vínculo de `0' a alguno de los nodos. 
En cada una de estas iteraciones almacenamos el peso de `0'.

\vspace{1em}
\noindent \textsc{Resultados}. El resultado no fue el esperado, ya que como se ve en el gráfico la curva de color xxx, el peso de `0' de no referenciar a nadie a referenciar a un nodo baja pero luego se mantiene constante, como si el impacto que genera en el peso de un nodo particular referenciar a una cantidad arbitraria de nodos fuera comparable con referenciar a un único nodo. 

Pensamos que quizás en un ambiente más `real' con relaciones aleatorias entre los demás nodos del sistema podría alterar nuestros resultados, por ello reestructuramos el test para que además de las relaciones previamente mencionadas los nodos [1 a 20] estén conectados entre sí de manera aleatoria. Para obtener resultados significativos que no esten `contaminados' por la aleatoreidad corrimos el test 10 veces, sumamos el resultado de cada una de las iteraciones y calculamos su promedio.
El resultado obtenido fue similar al resultado previo por ende deducimos que no referenciar a ningún nodo es la estrategia óptima y que a partir de referenciar a uno o más nodos en un ambiente aleatorio genera, en promedio, el mismo impacto en el peso de la la página que referencia.
\noindent \textsc{Resultados}.
